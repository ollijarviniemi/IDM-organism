This repository contains the data for "[Instrumental deception and manipulation in LLMs - a case study](https://www.alignmentforum.org/posts/vTJt3Rw44HXotHBxu/instrumental-deception-and-manipulation-in-llms-a-case-study)" and the code and prompts to reproduce the results.

Consider first looking at the file EXAMPLE.txt to see the baseline prompt and three completions to it.

You may then wish to look at the other completions at completions/. For the DMGI-completions in particular, see the file DMGI-completions.txt

Instructions for running sample_variants.py:
- Install the necessary Python modules. Note: you may wish to set up a virtual environment for this.
- Get an API key for Claude. Note: Claude is not available in all locations.

It should be clear enough how to modify the prompts and code to consider new variations.
